---
title: "Microsoft Copilot、DLPポリシーを回避して機密メールを無断要約——1月から継続中のバグ"
description: "Microsoft 365 Copilotに深刻なセキュリティバグが発覚。Sent ItemsとDraftsフォルダの機密ラベル付きメールを、DLPポリシーを無視して要約してしまう問題が2026年1月21日から継続中。修正ロールアウト中だが完了時期は未公表。"
publishedAt: "2026-02-18T20:00:00+09:00"
author: "AI Tools Hub"
category: "security"
lang: "ja"
tags: ["Microsoft", "Copilot", "セキュリティ", "DLP", "企業AI", "データ保護"]
featured: false
---

MicrosoftはMicrosoft 365 Copilotに深刻なセキュリティバグが存在することを認めた。BleepingComputerへの情報として公開されたサービス通知によると、Copilotの「work tab」チャット機能が機密ラベル（confidentiality label）付きのメールをDLP（データ損失防止）ポリシーを無視して要約してしまう問題が、2026年1月21日から継続中であることが判明した。

## 問題の概要

**影響範囲：**
- 対象フォルダ：OutlookのSent Items（送信済み）とDrafts（下書き）
- 問題の核心：機密ラベルが設定されたメールを自動処理しないよう指示するDLPポリシーを、Copilotが無視して要約する
- バグID：CW1226324
- 影響を受けるサービス：Microsoft 365 Copilot Chat（Word・Excel・PowerPoint・Outlook・OneNoteで展開中）

Microsoftは「コードの問題により、機密ラベルが設定されているにもかかわらず、送信済みフォルダと下書きフォルダのアイテムがCopilotに処理されてしまっている」と認めた。修正のロールアウトは2月初旬から段階的に開始されているが、完全な修正完了の時期や影響を受けたユーザー数・組織数については未公表のままだ。

## 企業セキュリティへの示唆

このバグは、AIアシスタントをエンタープライズ環境に展開する際の本質的な課題を浮き彫りにしている。組織がDLPやIRM（Information Rights Management）ポリシーを整備していても、AIが意図せずその境界を越えうるという問題は、AIガバナンスの設計段階から考慮すべき事項だ。

特に今回の問題が深刻なのは、以下の点だ：
- DLPポリシーは本来、機密情報の不正アクセスや外部漏洩を防ぐ重要なセキュリティレイヤー
- 機密ラベルは金融・法務・人事など高機密度情報に付与されることが多い
- Copilotが要約を生成することで、アクセス権のないユーザーがその内容を参照できる可能性がある

## 業界全体の構造的課題

同時期に発覚したClaude Sonnet 4.6のシステムカードにも、Computer Useにおけるプロンプトインジェクション攻撃の1回試行での成功率が8%（無制限試行では50%）であることが記載されている。AnthropicとMicrosoftという業界の主要プレイヤー両社で、AI機能のセキュリティ問題が表面化したことは、AIエージェントのエンタープライズ展開が新しいセキュリティリスクの層を生み出していることを示す。

企業がAIアシスタントを導入する際は、ツールの機能面だけでなく、既存のセキュリティポリシーとの整合性を詳細に検証するプロセスが欠かせない。

**現状の推奨対応（管理者向け）：**
- Microsoft 365管理センターでCW1226324の修正適用状況を確認
- 機密ラベルポリシーが設定されている環境では、修正完了まで機密メールへのCopilotアクセスを制限する設定を検討
- 影響範囲の確認のため、Copilotの使用ログを監査

**出典：** BleepingComputer / Microsoft 365サービス通知
